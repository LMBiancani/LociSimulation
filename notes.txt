NOTES - LociSimulation
github: https://github.com/LMBiancani/LociSimulation.git
Project="/scratch4/workspace/biancani_uri_edu-LociSimulation"

2025.10.09

ws_allocate -m biancani@uri.edu -r 5 -G pi_rsschwartz_uri_edu LociSimulation 30

Info: creating workspace.
/scratch4/workspace/biancani_uri_edu-LociSimulation
remaining extensions  : 5
remaining time in days: 30

Starting with mammal loci from https://github.com/LMBiancani/PlacentalPolytomy
Original Path to aligned loci:
"/data/schwartzlab/Biancani/PlacentalPolytomy/output/01_SISRS_loci_filtered"

2025.10.09

cd /scratch4/workspace/biancani_uri_edu-LociSimulation

copy mammal loci to scratch space:

transfer.sh
---------------------------------
#!/bin/bash
#SBATCH --job-name="tar_transfer"
#SBATCH --time=48:00:00  # walltime limit (HH:MM:SS)
#SBATCH --mail-user="biancani@uri.edu"
#SBATCH --mail-type=ALL
#SBATCH --nodes=1
#SBATCH --ntasks-per-node=1
#SBATCH -p uri-cpu
#SBATCH --cpus-per-task=1
#SBATCH --mem-per-cpu=6G

# Define source and destination directories
SOURCE_DIR="/data/schwartzlab/Biancani/PlacentalPolytomy/output/01_SISRS_loci_filtered"
DEST_DIR="/scratch4/workspace/biancani_uri_edu-LociSimulation/mammal_loci"

# Make sure the destination exists
mkdir -p "$DEST_DIR"
echo "Started at $(date)"

# Stream the directory (preserving its name) to scratch
tar -cf - -C "$(dirname "$SOURCE_DIR")" "$(basename "$SOURCE_DIR")" | pv | tar -xf - -C "$DEST_DIR"

echo "Finished at $(date)"
---------------------------------
sbatch transfer.sh
Submitted batch job 45655769

sacct -j 45655769 -o JobID,ExitCode,Elapsed,MaxRSS
JobID        ExitCode    Elapsed     MaxRSS
------------ -------- ---------- ----------
45655769          0:0   00:01:48
45655769.ba+      0:0   00:01:48   2114772K
45655769.ex+      0:0   00:01:48          0

mkdir /scratch4/workspace/biancani_uri_edu-LociSimulation/LociSimulation

github: https://github.com/LMBiancani/LociSimulation.git

2025.10.20

Use git subtree to copy Molly's updated simulation/machine learning scripts (and preserve commit history)
Molly's repo: https://github.com/mollyodonnellan/PML.git

cd /scratch4/workspace/biancani_uri_edu-LociSimulation/LociSimulation
git subtree add --prefix=Scripts https://github.com/mollyodonnellan/PML.git main

Mammal data is too large for AMAS so script needs updating to run through loci in batches.

run_amas.py is a custom batch concatenation wrapper around AMAS.
It processes FASTA alignments in chunks of 1000 files at a time (to avoid overloading AMAS input limitations), concatenates them, and appends the results into cumulative files.
Outputs:
concatenated.fasta
partitions.txt

cd /scratch4/workspace/biancani_uri_edu-LociSimulation/LociSimulation/Scripts/0_data_prep

nano run_amas.py
---------------------------------
#!/usr/bin/env python3
"""
run_amas.py
------------
Concatenates FASTA alignments in batches using AMAS (to avoid overloading AMAS input limitations).
Creates a concatenated alignment file and a corresponding partition file:
concatenated.fasta
partitions.txt

Usage:
    python run_amas.py <fasta_folder> <num_cores> <path_to_AMAS.py>
"""

import sys
import glob
import subprocess
import os

# --- Input arguments ---
fasta_folder = sys.argv[1]
total_cores = sys.argv[2]
amas = sys.argv[3]

# --- Collect all fasta files ---
files = glob.glob(os.path.join(fasta_folder, "*.fasta"))
files.sort()  # ensure consistent, reproducible order

batch_size = 1000
batch_outputs = []
batch_parts = []

count = 0
fileList = []
batch_num = 1

# --- Process loci in batches ---
for f in files:
    fileList.append(f)
    count += 1

    if count == batch_size:
        batch_fasta = f"amas_batch_{batch_num}.fasta"
        batch_part = f"partitions_batch_{batch_num}.txt"

        cmd = (
            f"python3 {amas} concat "
            f"-f fasta -d dna --out-format fasta --part-format raxml "
            f"-i {' '.join(fileList)} "
            f"-c {total_cores} -t {batch_fasta} -p {batch_part}"
        )
        print(f"\n=== Running AMAS on batch {batch_num} ({len(fileList)} files) ===")
        subprocess.call(cmd, shell=True)

        batch_outputs.append(batch_fasta)
        batch_parts.append(batch_part)
        fileList = []
        count = 0
        batch_num += 1

# --- Final partial batch (if any) ---
if len(fileList) > 0:
    batch_fasta = f"amas_batch_{batch_num}.fasta"
    batch_part = f"partitions_batch_{batch_num}.txt"

    cmd = (
        f"python3 {amas} concat "
        f"-f fasta -d dna --out-format fasta --part-format raxml "
        f"-i {' '.join(fileList)} "
        f"-c {total_cores} -t {batch_fasta} -p {batch_part}"
    )
    print(f"\n=== Running AMAS on final batch {batch_num} ({len(fileList)} files) ===")
    subprocess.call(cmd, shell=True)

    batch_outputs.append(batch_fasta)
    batch_parts.append(batch_part)

# --- Final concatenation across all batches ---
print("\n=== Performing final concatenation across batches ===")

cmd_final = (
    f"python3 {amas} concat "
    f"-f fasta -d dna --out-format fasta --part-format raxml "
    f"-i {' '.join(batch_outputs)} "
    f"-c {total_cores} -t concatenated.fasta -p partitions.txt"
)
subprocess.call(cmd_final, shell=True)

# --- Cleanup temporary batch files ---
print("\n=== Cleaning up intermediate files ===")
for f in batch_outputs + batch_parts:
    try:
        os.remove(f)
    except OSError:
        print(f"Warning: could not remove {f}")

print("\n=== run_amas.py execution completed. ===")
print("Output files:")
print(" - concatenated.fasta")
print(" - partitions.txt\n")
---------------------------------

0.0_amas_concat.sh runs AMAS on an empirical dataset to concatenate input fasta files and prepare partitions ahead of IQTree run.
Uses a helper Python script (run_amas.py), which wraps around the AMAS.py concat command.

cd /scratch4/workspace/biancani_uri_edu-LociSimulation/LociSimulation/Scripts/0_data_prep

nano 0.0_amas_concat.sh
---------------------------------
#!/bin/bash
#SBATCH --job-name="AMAS"
#SBATCH --time=2:00:00  # walltime limit (HH:MM:SS)
#SBATCH --nodes=1   # number of nodes
#SBATCH --ntasks-per-node=1   # processor core(s) per node
#SBATCH --cpus-per-task=1
#SBATCH --mem-per-cpu=10G
#SBATCH -p uri-cpu
#SBATCH --mail-user="biancani@uri.edu" #CHANGE THIS to your user email address
#SBATCH --mail-type=ALL

# --- Variables ---
# Path to project directory:
Project="/scratch4/workspace/biancani_uri_edu-LociSimulation"
# Path to scripts directory:
Scripts="$Project/LociSimulation/Scripts"
# Path to output directory (will be created if necessary)
Output="$Project/output/mammals"
# Path to aligned loci in fasta format:
Data="$Project/mammal_loci/01_SISRS_loci_filtered"
# Path to AMAS executable:
AMAS="/project/pi_rsschwartz_uri_edu/Biancani/Software/AMAS/amas/AMAS.py"
# Number of processor cores per node:
Cores=$(echo $SLURM_TASKS_PER_NODE | sed 's/(x.*)//')

module purge
module load uri/main Python/3.7.4-GCCcore-8.3.0

date
mkdir -p ${Output}/0.0_concatenated
cd ${Output}/0.0_concatenated

#Concatenate input fasta files and prepare partitions ahead of IQTree run
python3 ${Scripts}/0_data_prep/run_amas.py ${Data} ${Cores} ${AMAS}

date
---------------------------------
sbatch 0.0_amas_concat.sh
Submitted batch job 49112018
JobID        ExitCode    Elapsed     MaxRSS
------------ -------- ---------- ----------
49112018          0:0   00:01:39
49112018.ba+      0:0   00:01:39   5584204K
49112018.ex+      0:0   00:01:40          0

cd /scratch4/workspace/biancani_uri_edu-LociSimulation/LociSimulation/Scripts/0_data_prep

0.1_iqtree_empirical.sh will use iqtree to infer an empirical tree.

nano 0.1_iqtree_empirical.sh
---------------------------------
#!/bin/bash
#SBATCH --job-name="IQTREE"
#SBATCH --time=96:00:00  # walltime limit (HH:MM:SS)
#SBATCH --nodes=1
#SBATCH --ntasks=1
#SBATCH --cpus-per-task=24
#SBATCH --mem=250G
#SBATCH -p uri-cpu
#SBATCH --mail-user="biancani@uri.edu" #CHANGE THIS to your user email address
#SBATCH --mail-type=ALL

# --- Variables ---
# Path to project directory:
Project="/scratch4/workspace/biancani_uri_edu-LociSimulation"
# Path to output directory
Output="$Project/output/mammals"
# Path to IQTREE executable:
IQTREE="/project/pi_rsschwartz_uri_edu/Biancani/Software/iqtree-2.1.2-Linux/bin/iqtree2"
# Path to output files from 0.0_amas_concat.sh
Input="$Output/0.0_concatenated"
# Number of cpus per task:
Threads=${SLURM_CPUS_PER_TASK}

module purge

date
mkdir -p ${Output}/0.1_empirical_tree
cd ${Output}/0.1_empirical_tree

# --- Check for input files produced by 0.0_amas_concat.sh---

if [[ ! -f "$Input/concatenated.fasta" || ! -f "$Input/partitions.txt" ]]; then
    echo "Error: concatenated.fasta or partitions.txt not found in ${Input}"
    exit 1
fi

# --- Run IQ-TREE ---
# Flags:
#   -nt: number of CPU threads
#   -spp: partition file allowing different evolutionary rates per partition
#   -pre: prefix for output files
#   -m MFP: ModelFinder Plus for best-fit model selection
#   -bb: ultrafast bootstrap replicates
#   -alrt: SH-like approximate likelihood test replicates

${IQTREE} -nt ${Threads} \
    -s $Input/concatenated.fasta \
    -spp $Input/partitions.txt \
    -pre inferenceEmpirical \
    -m MFP -bb 1000 -alrt 1000

date
---------------------------------
sbatch 0.1_iqtree_empirical.sh
Submitted batch job 47065851
sacct -j 47065851 -o JobID,ExitCode,Elapsed,MaxRSS
JobID        ExitCode    Elapsed     MaxRSS
------------ -------- ---------- ----------
47065851          0:0 2-17:22:51
47065851.ba+      0:0 2-17:22:51 149134624K
47065851.ex+      0:0 2-17:22:51       256K

2025.11.21

cd /scratch4/workspace/biancani_uri_edu-LociSimulation/LociSimulation/Scripts/1_prep_empirical_tree

nano install.packages.R
---------------------------------
# Capture command-line arguments (package names to check and install)
args <- commandArgs(trailingOnly = TRUE)

if (length(args) == 0) {
  stop("Error: No package names provided as arguments. Exiting.", call. = FALSE)
}

# The packages to install are now in the 'args' vector
packages_to_install <- args

# Function to check, install, and load packages
install_and_load <- function(pkg) {
  # Check if the package is installed
  if (!requireNamespace(pkg, quietly = TRUE)) {
    message(paste("Package", pkg, "not found. Installing..."))
    # Install the package from CRAN
    install.packages(pkg, dependencies = TRUE, repos = "https://cloud.r-project.org")
  } else {
    message(paste("Package", pkg, "is already installed."))
  }

  # Load the package (library function)
  library(pkg, character.only = TRUE)
  message(paste("Package", pkg, "loaded successfully."))
}

# Apply the function to the list of packages
invisible(sapply(packages_to_install, install_and_load))
---------------------------------

nano empirical_tree_processor.R
---------------------------------
## Capture Command Line Arguments

# Arguments must be passed in the following order:
# [1] mod_write_tree2     (Path to modified.write.tree2.R - script that adjusts how ape handles tree files)
# [2] treefile            (Path to the input .treefile - generated by 0.1_iqtree_empirical.sh)
# [3] Output1.0           (Base directory for output files)
# [4] out_tip             (The tip name to use as the outgroup for rooting)
# [5] tree_depth          (Estimated age in years of most recent common ancestor of all species in the tree)
# [6] gen_time            (Estimated generation time in years for all species in the tree)
# [7] simphy_seed1       (First random number seed for generate_params.txt)
# [8] simphy_seed2       (Second random number seed for generate_params.txt)

args <- commandArgs(trailingOnly = TRUE)

# Check if the correct number of arguments was provided
if (length(args) < 8) {
  stop("Error: Not enough arguments provided. Expected 8.", call. = FALSE)
}

# Assign arguments to variables
mod_write_tree2 <- args[1]
treefile <- args[2]
Output1.0 <- args[3]
out_tip <- args[4]
simphy_seed1 <- args[7]
simphy_seed2 <- args[8]

# Calculate the scale factor (Total Generations) from args[5] (depth) and args[6] (gen_time)
scale_factor <- as.numeric(args[5])/as.numeric(args[6])

# --- 2. Load Libraries and Setup ---

library(ape)
library(ggplot2)
library(geiger)
library(ggtree)

## Force a headless friendly bitmap device for the session
options(bitmapType = "cairo")

# Adjust path to modified.write.tree2.R
source(mod_write_tree2)
assignInNamespace(".write.tree2", .write.tree2, "ape")

# --- 3. Process and Save Empirical Tree ---

# Empirical tree:
tree <- read.tree(treefile)

# Root the tree and save the check image
tree <- root(tree, outgroup = out_tip)
p <- ggtree(tree) + theme_tree2() + geom_tiplab()
ggsave(p, file=paste0(Output1.0, "/tree_check_root.png"))

# Check the tree rooted correctly. Then transform to ultrametric and rescale

tree_um <- chronos(tree)
class(tree_um) <- "phylo" # Ensure it is a 'phylo' object after chronos
tree_um <- rescale(tree_um, model = "depth", scale_factor)

# Save the ultrametric tree check image
q <- ggtree(tree_um) + theme_tree2() + geom_tiplab()
ggsave(q, file=paste0(Output1.0, "/tree_um.png"))

# --- 4. Prepare for SimPhy and Write Outputs ---

# Replace labels with numbers, strip node labels, and write out the tree
tree_um$tip.label <- as.character(1:length(tree_um$tip.label))
tree_um$node.label <- NULL
write.tree(tree_um, paste0(Output1.0, "/s_tree.trees"), digits=8)

# Write the seeds for subsequent dataset parameter simulations
write(c(simphy_seed1, simphy_seed2), paste0(Output1.0, "/generate_params.txt"))

print("Tree processing complete and output files saved.")
---------------------------------


## INPUTS for empirical_tree_processor.R

# generation scaling factor: Number of generations in the tree: absolute tree age in years divided by average generation time of species in the tree.
total tree depth (years) / average generation time (years)

# total tree depth: age of most recent common ancestor of all species in the tree.
For this mammal data, this would be the age of Theria or age of the common ancestor of placental mammals (ingroup) and marsupials (outgroup)
total tree depth (years) is estimated to be 168 mya
Citations:
2019 - Upham NS, Esselstyn JA, Jetz W (2019) Inferring the mammal tree: Species-level sets of phylogenies for questions in ecology, evolution, and conservation. PLoS Biol 17(12): e3000494.https://doi.org/10.1371/journal.pbio.3000494
168 Fig 1
2017 - Thomas L. Dunwell, Jordi Paps, Peter W. H. Holland; Novel and divergent genes in the evolution of placental mammals. Proc Biol Sci 1 October 2017; 284 (1864): 20171357. https://doi.org/10.1098/rspb.2017.1357
140-191 "The common ancestor of placentals and marsupials dates to approximately 140 – 191 million years ago (Ma)"

tree_depth=168000000

# average generation time (years)
We used a estimated generation time of 4.5 years for Theria. This value is chosen not as the arithmetic mean or median of all extant species (which is skewed by small-bodied rodents and bats), but as a phylogenetically-informed effective generation time that is consistent with the estimated rate of mutation at the deepest nodes of the mammalian tree. This approach accounts for the allometric relationship between body mass and generation length, a relationship thoroughly characterized across Mammalia [cite Pacifici et al., 2013]. Our chosen rate falls within the range utilized by major phylogenomic studies (e.g., Meredith et al., 2011), which established evolutionary rates for ancestral nodes that are consistent with a moderately sized stem mammal ancestor and a generation time in the 4–5 year range."
Citation:
Pacifici, Michela, et al. "Generation length for mammals." Nature Conservation 5 (2013): 89-94.
Meredith, Robert W., et al. "Impacts of the Cretaceous Terrestrial Revolution and KPg extinction on mammal diversification." science 334.6055 (2011): 521-524.

gen_time=4.5

nano 1.0_format_tree.sh
---------------------------------
#!/bin/bash
#SBATCH --job-name="process_tree"
#SBATCH --time=72:00:00                # Walltime limit (HH:MM:SS)
#SBATCH --nodes=1                      # Number of nodes
#SBATCH --ntasks=1                     # Total number of tasks (processes)
#SBATCH --cpus-per-task=2              # Number of CPU cores per task
#SBATCH --mem-per-cpu=6G               # Memory per cpu
#SBATCH --mail-user="biancani@uri.edu" # CHANGE TO user email address
#SBATCH --mail-type=ALL
#SBATCH -p uri-cpu                     # Partition/queue to submit job to

# --- Variables ---
# Path to project directory:
Project="/scratch4/workspace/biancani_uri_edu-LociSimulation"
# Path to scripts directory:
Scripts="$Project/LociSimulation/Scripts"
# Path to modified.write.tree2.R (script that adjusts how ape handles tree files)
mod_write_tree2=$Scripts/2_simulation_scripts/modified.write.tree2.R
# Path to output directory
Output="$Project/output/mammals"
# Path to treefile generated by 0.1_iqtree_empirical.sh
treefile=$Output/0.1_empirical_tree/inferenceEmpirical.treefile
# List of necessary R packages (separated by spaces)
R_packages="ape ggplot2 geiger ggtree"
# Total tree depth: Estimated age (in years) of most recent common ancestor of all species in the tree
tree_depth=168000000
# Generation time: Estimated generation time (in years) of all species in the tree:
gen_time=4.5
# Taxon (tip name) to use as the outgroup for rooting
out_tip="Didelphis_virginiana"
# Random number seeds for generate_params.txt
simphy_seed1=12345
simphy_seed2=67890

# create output subdirectory:
Output1.0=$Output/1.0_formatted_empirical_tree/
mkdir -p $Output1.0
cd $Output1.0

module purge
module load uri/main
module load R-bundle-Bioconductor/3.15-foss-2021b-R-4.2.0

## Install R packages

# add local space for R packages (won't ask about install location):
mkdir -p ~/R-packages
export R_LIBS=~/R-packages

# install R packages
Rscript ${Scripts}/1_prep_empirical_tree/install.packages.R $R_packages

## Process Empirical tree
Rscript $Scripts/1_prep_empirical_tree/empirical_tree_processor.R $mod_write_tree2 $treefile $Output1.0 $out_tip $tree_depth $gen_time $simphy_seed1 $simphy_seed2

date
---------------------------------
